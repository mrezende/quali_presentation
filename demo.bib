@article{Knuth92,
        author = "D.E. Knuth",
        title = "Two notes on notation",
        journal = "Amer. Math. Monthly",
        volume = "99",
        year = "1992",
        pages = "403--422",
}

@book{ConcreteMath,
        author = "R.L. Graham and D.E. Knuth and O. Patashnik",
        title = "Concrete mathematics",
        publisher = "Addison-Wesley",
        address = "Reading, MA",
        year = "1989"
}

@unpublished{Simpson,
        author = "H. Simpson",
        title = "Proof of the {R}iemann {H}ypothesis",
        note = "preprint (2003), available at
        \texttt{http://www.math.drofnats.edu/riemann.ps}",
        year = "2003"
}

@incollection{Er01,
        author = "P. Erd{\H o}s",
        title = "A selection of problems and results in combinatorics",
        booktitle = "Recent trends in combinatorics (Matrahaza, 1995)",
        publisher = "Cambridge Univ. Press",
        address = "Cambridge",
        pages = "1--6",
        year = "1995"
}
@article{greenwade93,
    author  = "George D. Greenwade",
    title   = "The {C}omprehensive {T}ex {A}rchive {N}etwork ({CTAN})",
    year    = "1993",
    journal = "TUGBoat",
    volume  = "14",
    number  = "3",
    pages   = "342--351"
}

@article{cambronero-deep-learning-code-search:2019,
  author    = {Jos{\'{e}} Cambronero and
               Hongyu Li and
               Seohyun Kim and
               Koushik Sen and
               Satish Chandra},
  title     = {When Deep Learning Met Code Search},
  journal   = {CoRR},
  volume    = {abs/1905.03813},
  year      = {2019},
  url       = {http://arxiv.org/abs/1905.03813},
  archivePrefix = {arXiv},
  eprint    = {1905.03813},
  timestamp = {Wed, 17 Jul 2019 09:44:59 +0200},
  biburl    = {https://dblp.org/rec/bib/journals/corr/abs-1905-03813},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{Gu-deep-code-search:2018,
 author = {Gu, Xiaodong and Zhang, Hongyu and Kim, Sunghun},
 title = {Deep Code Search},
 booktitle = {Proceedings of the 40th International Conference on Software Engineering},
 series = {ICSE '18},
 year = {2018},
 isbn = {978-1-4503-5638-1},
 location = {Gothenburg, Sweden},
 pages = {933--944},
 numpages = {12},
 url = {http://doi.acm.org/10.1145/3180155.3180167},
 doi = {10.1145/3180155.3180167},
 acmid = {3180167},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {code search, deep learning, joint embedding},
}

@inproceedings{iyer-etal-2016-summarizing,
    title = "Summarizing Source Code using a Neural Attention Model",
    author = "Iyer, Srinivasan  and
      Konstas, Ioannis  and
      Cheung, Alvin  and
      Zettlemoyer, Luke",
    booktitle = "Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    month = aug,
    year = "2016",
    address = "Berlin, Germany",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/P16-1195",
    doi = "10.18653/v1/P16-1195",
    pages = "2073--2083",
}

@inproceedings{yao-2018,
 author = {Yao, Ziyu and Weld, Daniel S. and Chen, Wei-Peng and Sun, Huan},
 title = {StaQC: A Systematically Mined Question-Code Dataset from Stack Overflow},
 booktitle = {Proceedings of the 2018 World Wide Web Conference},
 series = {WWW '18},
 year = {2018},
 isbn = {978-1-4503-5639-8},
 location = {Lyon, France},
 pages = {1693--1703},
 numpages = {11},
 url = {https://doi.org/10.1145/3178876.3186081},
 doi = {10.1145/3178876.3186081},
 acmid = {3186081},
 publisher = {International World Wide Web Conferences Steering Committee},
 address = {Republic and Canton of Geneva, Switzerland},
 keywords = {deep neural networks, natural language question answering, question-code pairs, stack overflow},
}

@inproceedings{feng-etal-2018-pathologies,
    title = "Pathologies of Neural Models Make Interpretations Difficult",
    author = "Feng, Shi  and
      Wallace, Eric  and
      Grissom II, Alvin  and
      Iyyer, Mohit  and
      Rodriguez, Pedro  and
      Boyd-Graber, Jordan",
    booktitle = "Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing",
    month = oct # "-" # nov,
    year = "2018",
    address = "Brussels, Belgium",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/D18-1407",
    doi = "10.18653/v1/D18-1407",
    pages = "3719--3728",
    abstract = "One way to interpret neural model predictions is to highlight the most important input features{---}for example, a heatmap visualization over the words in an input sentence. In existing interpretation methods for NLP, a word{'}s importance is determined by either input perturbation{---}measuring the decrease in model confidence when that word is removed{---}or by the gradient with respect to that word. To understand the limitations of these methods, we use input reduction, which iteratively removes the least important word from the input. This exposes pathological behaviors of neural models: the remaining words appear nonsensical to humans and are not the ones determined as important by interpretation methods. As we confirm with human experiments, the reduced examples lack information to support the prediction of any label, but models still make the same predictions with high confidence. To explain these counterintuitive results, we draw connections to adversarial examples and confidence calibration: pathological behaviors reveal difficulties in interpreting neural models trained with maximum likelihood. To mitigate their deficiencies, we fine-tune the models by encouraging high entropy outputs on reduced examples. Fine-tuned models become more interpretable under input reduction, without accuracy loss on regular examples.",
}
